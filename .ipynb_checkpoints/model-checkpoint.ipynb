{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08d8534-0cb5-4ed7-827a-87f0a306d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Числовые данные: 28\n",
      "Категориальные данные: 24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = 'данные.xlsx'\n",
    "data = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "data_filtered = data[data['Статус поиска'] != 'в процессе']\n",
    "\n",
    "target = data_filtered['Общее время поиска']\n",
    "\n",
    "# Разделение данных на числовые и категориальные признаки\n",
    "numeric_features = data_filtered.select_dtypes(include=['int64', 'float64']).drop(columns=['Общее время поиска'])\n",
    "categorical_features = data_filtered.select_dtypes(include=['object'])\n",
    "\n",
    "print(\"Числовые данные: \" + str(numeric_features.shape[1]))\n",
    "print(\"Категориальные данные: \" + str(categorical_features.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ebda86-8c14-427d-a957-67d87ba343b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nbagr\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Кодируем категориальные признаки с помощью OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded_categorical = encoder.fit_transform(categorical_features)\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_features.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bef4f2c-11f1-4af4-877e-8d1c187316ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Заполнение пропусков для числовых данных: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [10:50<00:00, 25.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в каждом столбце:\n",
      "Столбец: Наименование расщелины, Пропуски: 0\n",
      "Столбец: Количество труб, Пропуски: 0\n",
      "Столбец: Количество дополнительных отвилков, Пропуски: 0\n",
      "Столбец: Количество пилотных отвилков, Пропуски: 0\n",
      "Столбец: Глубина по отвилку, Пропуски: 0\n",
      "Столбец: Глубина первого отвилка, Пропуски: 0\n",
      "Столбец: Путь поиска в первом отвилке, Пропуски: 0\n",
      "Столбец: Общее время активного поиска, Пропуски: 0\n",
      "Столбец: Общее время простоев, Пропуски: 0\n",
      "Столбец: Количество аварий, Пропуски: 0\n",
      "Столбец: Количество брака, Пропуски: 0\n",
      "Столбец: Количество геологических осложнений, Пропуски: 0\n",
      "Столбец: Количество осложнений, Пропуски: 0\n",
      "Столбец: Количество простоев по метеоусловиям, Пропуски: 0\n",
      "Столбец: Количество простоев, Пропуски: 0\n",
      "Столбец: Количество ремонтов, Пропуски: 0\n",
      "Столбец: Количество простоев без виновника, Пропуски: 0\n",
      "Столбец: Количество простоев по вине королевства, Пропуски: 0\n",
      "Столбец: Количество простоев в поиске, Пропуски: 0\n",
      "Столбец: Количество простоев в наклонном поиске, Пропуски: 0\n",
      "Столбец: Количество простоев по зельям, Пропуски: 0\n",
      "Столбец: Количество простоев в контроле поиска, Пропуски: 0\n",
      "Столбец: Количество простоев в конце расщелины, Пропуски: 0\n",
      "Столбец: Количество простоев по долбилам, Пропуски: 0\n",
      "Столбец: Количество простоев по вине исследователей, Пропуски: 0\n",
      "Столбец: Количество простоев по креплениям, Пропуски: 0\n",
      "Столбец: Количество простоев (прочие), Пропуски: 0\n",
      "Столбец: Общий путь поиска, Пропуски: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Заполнение пропусков для числовых признаков с использованием RandomForestRegressor\n",
    "for column in tqdm(numeric_features.columns[numeric_features.isna().any()], desc=\"Заполнение пропусков для числовых данных\"):\n",
    "    data_no_nan = numeric_features.dropna(subset=[column])   # строки без пропусков в текущем столбце\n",
    "    data_nan = numeric_features[numeric_features[column].isna()] # строки с пропусками в текущем столбце\n",
    "\n",
    "    # Если нет строк для обучения модели, пропускаем этот столбец\n",
    "    if data_no_nan.empty or data_nan.empty:\n",
    "        continue\n",
    "    \n",
    "    # Используем SimpleImputer для временного заполнения остальных пропусков\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train = imputer.fit_transform(data_no_nan.drop(columns=[column]))\n",
    "    y_train = data_no_nan[column]\n",
    "    \n",
    "    # Инициализируем и обучаем модель\n",
    "    model = RandomForestRegressor(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Применяем модель для предсказания пропущенных значений в текущем столбце\n",
    "    X_test = imputer.transform(data_nan.drop(columns=[column]))\n",
    "    predicted_values = model.predict(X_test)\n",
    "    \n",
    "    # Заполняем пропуски предсказанными значениями\n",
    "    numeric_features.loc[data_nan.index, column] = predicted_values\n",
    "\n",
    "# Нормализуем числовые признаки с заполненными пропусками\n",
    "scaler = StandardScaler()\n",
    "scaled_numeric = scaler.fit_transform(numeric_features)\n",
    "# Нормализуем числовые признаки и сохраняем исходные индексы\n",
    "scaled_numeric_df = pd.DataFrame(scaler.fit_transform(numeric_features), columns=numeric_features.columns, index=numeric_features.index)\n",
    "\n",
    "# Проверка на наличие пропусков после заполнения\n",
    "missing_data = numeric_features.isna().sum()\n",
    "\n",
    "print(\"Количество пропусков в каждом столбце:\")\n",
    "for column, count in missing_data.items():\n",
    "    print(f\"Столбец: {column}, Пропуски: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e5ed29-45d1-48e5-af8a-9a51eea240a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Заполнение пропусков для категориальных данных: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:44<00:00, 11.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в каждом категориальном столбце после заполнения:\n",
      "Столбец: Наименование королевства, Пропуски: 0\n",
      "Столбец: Наименование земли, Пропуски: 0\n",
      "Столбец: Наименование хребта, Пропуски: 0\n",
      "Столбец: Цель, Пропуски: 0\n",
      "Столбец: Тип расщелины, Пропуски: 0\n",
      "Столбец: Категория расщелины, Пропуски: 0\n",
      "Столбец: Назначение расщелины, Пропуски: 0\n",
      "Столбец: Участки, Пропуски: 0\n",
      "Столбец: Тип отвилка, Пропуски: 0\n",
      "Столбец: Технологическая особенность, Пропуски: 0\n",
      "Столбец: Статус поиска, Пропуски: 0\n",
      "Столбец: Помощник по контролю поиска, Пропуски: 0\n",
      "Столбец: Помощник по поиску, Пропуски: 0\n",
      "Столбец: Помощник по наклонным расщелинам, Пропуски: 0\n",
      "Столбец: Помощник по зельям, Пропуски: 0\n",
      "Столбец: Помощник по долбилам, Пропуски: 0\n",
      "Столбец: Помощник по исследованиям, Пропуски: 0\n",
      "Столбец: Помощник по укреплению, Пропуски: 0\n",
      "Столбец: Помощник по огненным заклятиям, Пропуски: 0\n",
      "Столбец: Помощник по подвескам, Пропуски: 0\n",
      "Столбец: Помощник по вырезке окна, Пропуски: 0\n",
      "Столбец: Тип инструмента, Пропуски: 0\n",
      "Столбец: Дата начала поиска, Пропуски: 0\n",
      "Столбец: Дата окончания поиска, Пропуски: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Кодируем категориальные признаки, сохраняем индексы\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_features.columns), index=categorical_features.index)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for column in tqdm(categorical_features.columns[categorical_features.isna().any()], desc=\"Заполнение пропусков для категориальных данных\"):\n",
    "    data_no_nan = data_filtered.dropna(subset=[column])\n",
    "    data_nan = data_filtered[data_filtered[column].isna()]\n",
    "\n",
    "    if data_no_nan.empty or data_nan.empty:\n",
    "        continue\n",
    "\n",
    "    # Создаем обучающие и тестовые выборки с совпадающими индексами\n",
    "    X_train = pd.concat([scaled_numeric_df.loc[data_no_nan.index], encoded_categorical_df.loc[data_no_nan.index]], axis=1)\n",
    "    y_train = data_no_nan[column]\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = pd.concat([scaled_numeric_df.loc[data_nan.index], encoded_categorical_df.loc[data_nan.index]], axis=1)\n",
    "    predicted_values = model.predict(X_test)\n",
    "\n",
    "    categorical_features.loc[data_nan.index, column] = predicted_values\n",
    "\n",
    "# Проверка пропусков после заполнения\n",
    "missing_data_categorical = categorical_features.isna().sum()\n",
    "print(\"Количество пропусков в каждом категориальном столбце после заполнения:\")\n",
    "for column, count in missing_data_categorical.items():\n",
    "    print(f\"Столбец: {column}, Пропуски: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208c5ee4-0eaa-46fb-b568-1990b5c4b878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк с пропусками в таргете: 5\n",
      "Количество строк с пропущенными таргетами удалено: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Расчет корреляции: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12108/12108 [00:02<00:00, 4491.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция признаков с целевой переменной:\n",
      "Общее время активного поиска              0.669355\n",
      "Общее время простоев                      0.618919\n",
      "Количество простоев в поиске              0.521167\n",
      "Количество ремонтов                       0.514791\n",
      "Количество простоев                       0.475181\n",
      "Общий путь поиска                         0.351306\n",
      "Цель_разведка                             0.309731\n",
      "Количество брака                          0.303616\n",
      "Глубина по отвилку                        0.301359\n",
      "Количество простоев в наклонном поиске    0.267502\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Объединяем числовые и категориальные данные в один DataFrame\n",
    "features = pd.concat([scaled_numeric_df, encoded_categorical_df], axis=1)\n",
    "\n",
    "# Проверка на пропуски в таргете\n",
    "print(f\"Количество строк с пропусками в таргете: {target.isna().sum()}\")\n",
    "\n",
    "# Удаляем строки с пропусками в таргете\n",
    "features['Общее время поиска'] = target\n",
    "features = features.dropna(subset=['Общее время поиска'])\n",
    "\n",
    "# Выводим количество удаленных строк\n",
    "print(f\"Количество строк с пропущенными таргетами удалено: {target.isna().sum()}\")\n",
    "\n",
    "# Берем случайную 40% выборку данных\n",
    "sample_features = features.sample(frac=0.4, random_state=0)\n",
    "\n",
    "# Проверка на пропуски и константные признаки\n",
    "sample_features = sample_features.dropna(axis=1, how='any')  # Удаляем столбцы с пропусками\n",
    "sample_features = sample_features.loc[:, sample_features.nunique() > 1]  # Удаляем константные признаки\n",
    "\n",
    "# Подготовка пустой матрицы корреляции для заполнения с прогрессом\n",
    "correlation_with_target = pd.Series(index=sample_features.columns[:-1])\n",
    "\n",
    "# Рассчитываем корреляцию каждого признака с таргетом по выборке, добавляя прогресс-бар\n",
    "for column in tqdm(sample_features.columns[:-1], desc=\"Расчет корреляции\"):\n",
    "    correlation_with_target[column] = sample_features[column].corr(sample_features['Общее время поиска'])\n",
    "\n",
    "# Сортируем и выводим корреляции с целевой переменной\n",
    "correlation_with_target = correlation_with_target.sort_values(ascending=False)\n",
    "print(\"Корреляция признаков с целевой переменной:\")\n",
    "print(correlation_with_target[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e791eaf-7678-427c-b53b-d5f68da30190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Вычисляем матрицу корреляции для этой случайной выборки\n",
    "correlation_matrix = sample_features.corr()\n",
    "\n",
    "print(\"Матрица корреляции для случайной выборки:\")\n",
    "print(correlation_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
